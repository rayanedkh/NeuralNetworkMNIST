# RayaNN: a Neural Network for MNIST Digit Recognition from Scratch 

This repository contains a simple Multi-Layer Perceptron (MLP) used to classify handwritten digits from the MNIST dataset. The goal was to implement, train, save, and load a neural network from scratch using only fundamental Python libraries.

## ðŸ“‹ Project Overview

* **Objective**: Build and train a neural network from scratch to predict digits (0â€“9) from MNIST grayscale images (28Ã—28 pixels).
* **Dataset**: MNIST training set (`data_set/train.csv`, 42,000 samples) and test set (`data_set/test.csv`).
* **Model**: Two-layer MLP with ReLU activation and LogSoftmax output for numerical stability.
* **Training**: Gradient descent for 5,000 epochs with batch size 100.

## ðŸš€ Technologies & Dependencies
* **Programming Language**: Python

* **Core Libraries**:

  * `numpy` (array operations & saving/loading weights)
  * `pandas` (data handling)
  * `scipy.special.logsumexp` (stable softmax implementation)
  * `tqdm` (training progress bar)
  * `matplotlib` (visualizing predictions)

## ðŸ“‚ Project Structure

```bash
â”œâ”€â”€ README.md                  # Project documentation (this file)
â”œâ”€â”€ save_model.npz             # Binary file with learned weights (generated after training)
â””â”€â”€ RayaNN/        
    â”œâ”€â”€ rayane_nn.py           # Training script
    â”œâ”€â”€ main.py                # Used to test the model visually           
    â””â”€â”€ data_set/              # CSV files for training and test data
        â”œâ”€â”€ train.csv
        â””â”€â”€ test.csv

```
## ðŸ§© How the Neural Network Works

1. **Data Preprocessing**:

   * Load CSV, shuffle, normalize pixel values to `[0,1]`, split into training and dev sets.
2. **Model Architecture**:

   * **Layer 1**: Fully-connected (784â†’10) + ReLU.
   * **Layer 2**: Fully-connected (10â†’10) + LogSoftmax.
3. **Training Loop**:

   * Trained the model for 5,000 epochs with a batch size of 100.
   * Used a **loss function** and an **optimization function** implementing the **steepest descent** algorithm.
4. **Saving & Loading**:

   * Weights are saved in `save_model.npz` via `numpy.savez`.
   * Inference script loads `.npz`, rebuilds the model, and predicts a random test image.

## ðŸ“Š Results

* **Development accuracy**: \~92â€“93% after 5,000 epochs.
* **Inference**: Visual display of a randomly selected test image with predicted digit.

---

*Feel free to explore, modify the architecture, or extend to deeper networks!*
